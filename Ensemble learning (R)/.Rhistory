for (i in 1:nK){
k=K[i]
modtrain=knn(x,x,k,cl=y)
errtrain[i]=mean(modtrain!=y)
modtest=knn(x,xtest,k,cl=y)
errtest=mean(modtest!=ytest)
}
errtrain=rep(0,nK)
errtest=rep(0,nK)
for (i in 1:nK){
k=K[i]
modtrain=knn(x,x,k,cl=y)
errtrain[i]=mean(modtrain!=y)
modtest=knn(x,xtest,k,cl=y)
errtest=mean(modtest!=ytest)
}
plot(K,errtest,type="b",col="blue",xlab="nombre de voisins",ylab="err train test",pch=20,ylin=range(c(errtest,errtrain)))
K = c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
nK=length(K)
errtrain=rep(0,length=nK)
errtest=rep(0,length=nK)
for (i in 1:nK){
k=K[i]
modtrain=knn(x,x,k,cl=y)
errtrain[i]=mean(modtrain!=y)
modtest=knn(x,xtest,k,cl=y)
errtest=mean(modtest!=ytest)
}
plot(K,errtest,type="b",col="blue",xlab="nombre de voisins",ylab="err train test",pch=20,ylin=range(c(errtest,errtrain)))
lines(K,errtrain,type="b",col="red",pch="20")
for (i in 1:nK){
k=K[i]
modtrain=knn(x,x,k,cl=y)
errtrain[i]=mean(modtrain!=y)
modtest=knn(x,xtest,k,cl=y)
errtest=mean(modtest!=ytest)
}
plot(K,errtest,type="b",col="blue",xlab="nombre de voisins",ylab="err train test",pch=20,ylin=range(c(errtest,errtrain)))
errtest
K = c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
nK=length(K)
errtrain=rep(0,length=nK)
errtest=rep(0,length=nK)
for (i in 1:nK){
k=K[i]
modtrain=knn(x,x,k,cl=y)
errtrain[i]=mean(modtrain!=y)
modtest=knn(x,xtest,k,cl=y)
errtest[i]=mean(modtest!=ytest)
}
plot(K,errtest,type="b",col="blue",xlab="nombre de voisins",ylab="err train test",pch=20,ylin=range(c(errtest,errtrain)))
lines(K,errtrain,type="b",col="red",pch="20")
plot(K,errtest,type="b",col="blue",xlab="nombre de voisins",ylab="err train test",pch=20,ylin=range(c(errtest,errtrain)))
lines(K,errtrain,type="b",col="red",pch="20")
contour(px1,px2,prob15,level=0.5,labels="",xlab="x1",ylab="x2")
points(x,col=ifelse(y==1,"red","green"))
require(MASS)
set.seed(123)
centers=c(sample(1:10,5000,replace=TRUE),sample(11:20,5000,replace=TRUE))
means=mixture.example$means
means=means[centers,]
xtest=mvrnorm(10000,c(0,0),0.2*diag(2))
xtest=xtest+means
ytest=c(rep(0,5000),rep(1,5000))
K = c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
nK=length(K)
errtrain=rep(NA,length=nK)
errtest=rep(NA,length=nK)
for (i in 1:nK){
k=K[i]
modtrain=knn(x,x,k,cl=y)
errtrain[i]=mean(modtrain!=y)
modtest=knn(x,xtest,k,cl=y)
errtest[i]=mean(modtest!=ytest)
}
plot(K,errtest,type="b",col="blue",xlab="nombre de voisins",ylab="err train test",pch=20,ylin=range(c(errtest,errtrain)))
lines(K,errtrain,type="b",col="red",pch="20")
plot(K)
for (i in 1:nK){
k=K[i]
modtrain=knn(x,x,k,cl=y)
errtrain[i]=mean(modtrain!=y)
modtest=knn(x,xtest,k,cl=y)
errtest[i]=mean(modtest!=ytest)
}
plot(K,errtest,type="b",col="blue",xlab="nombre de voisins",ylab="err train test",pch=20,ylin=range(c(errtest,errtrain)))
lines(K,errtrain,type="b",col="red",pch="20")
set.seed(123)
centers = c(sample(1:10, 5000, replace=TRUE), sample(11:20, 5000, replace=TRUE))
means = mixture.example$means
means = means[centers, ]
xtest = mvrnorm(10000, c(0,0), 0.2*diag(2))
xtest = xtest + means
ytest = c(rep(0, 5000), rep(1, 5000))
K = c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
nK=length(K)
ErrTrain = rep(NA, length=nK)
ErrTest = rep(NA, length=nK)
for(i in 1:nK)
{
k=K[i]
modtrain=knn(x,x,k=k,cl=y)
ErrTrain[i]=mean(modtrain!=y)
modtest=knn(x,xtest,k=k,cl=y)
ErrTest[i]=mean(modtest!=ytest)
}
plot(K, ErrTest, type="b", col="blue",
xlab="nombre de voisins",
ylab="erreurs train et test", pch=20,
ylim=range(c(ErrTest,ErrTrain)))
lines(K,ErrTrain,type="b",col="red", pch=20)
legend("bottomright",lty=1,col=c("red","blue"), legend = c("train","test"))
help(corrplot)
help(ggplot)
install.packages("corrplot")
help(corrplot)
library(corrplot)
help(corrplot)
help(GGally)
install.packages("GGally")
help(car)
??car
install.packages("car")
library(corrplot)
library(GGally)
library(car)
seeds=read.table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt"))
seeds
names(seeds)=c("area","perimeter","compact","length","widhth","asym","lgroove","variety")
seeds
seed$variety=NULL
seeds$variety=NULL
seeds
help(pairs)
help(corrplot)
corrplot(seeds$area)
corrplot(seeds)
pairs(seeds)
ggpairs(seeds)
corrplot(seeds)
pairs(seeds)
ggpairs(seeds)
library(corrplot)
library(GGally)
library(car)
seeds=read.table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt"))
names(seeds)=c("area","perimeter","compact","length","widhth","asym","lgroove","variety")
seeds[,-8]
seeds
library(corrplot)
library(GGally)
library(car)
seeds=read.table(url("http://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt"))
names(seeds)=c("area","perimeter","compact","length","widhth","asym","lgroove","variety")
seeds=seeds[,-8]
seeds
pairs(seeds)
ggpairs(seeds)
corrplot(seeds)
help(corrplot)
corrplot(seeds,method="circle")
corrplot(cor(seeds),method="circle")
boxplot(seeds)
seeds=read.table(url("archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt"))
names(seeds)=c( "area","perimeter","compact","length","width","asym","lgroove","variety")
p=ncol(seeds)
pairs(seeds[,-p])
round(cor(seeds[,-p]),2)
library(corrplot)
corrplot(cor(seeds[,-p]), method="circle")
library(car)
scatterplotMatrix(as.matrix(seeds[,-p]))
boxplot(seeds[,-p])
library(GGally)
ggpairs(seeds[,-p])
n=nrow(seeds)
X = scale(seeds[,-p],center=TRUE,scale=TRUE)/sqrt((n-1)/n)
apply(X^2,2,mean)  # vérification
C = cor(X)
C = cor(X)
v=eig(X)
v=eigen(X)
eigen(X)
eigen(C)
v=eigen(C)
plt(v)
plot(v)
v=eigen(C)
sum=sum(v)
inert=v/sum
v=eigen(C)
C = cor(X)
v=eigen(C)
sum=sum(v)
v
sum=sum(v$values)
inert=v/sum
inert=v$values/sum
inert
v=eigen(C)
v
sum=sum(v$values)
inert=v$values/sum
inert
# Calcul des coordonnées des individus sur les axes principaux
vectp = eigen(C)$vectors
apply(vectp,2,function(x){sum(x^2)}) # vecteurs normés
F1 = X%*%vectp[,1]                   # composante principale 1er axe
F2 = X%*%vectp[,2]                   # composante principale 2ème axe
X%*%vectp                            # composantes principales sur tous les axes
# Calcul des coordonnées des variables sur les axes principaux
G1 = cor(X,F1)
G2 = cor(X,F2)
v1 = 1/sqrt(valp[1]) * F1
G1prime = cor(X,v1)
plot(F1,F2,xlab="Dim1",ylab="Dim2",type="n",
main="Nuage des individus")     # juste les axes
abline(v=0,h=0,lty=2)
val_ind=1:n                          # les labels
text(F1,F2,val_ind)
v1 = 1/sqrt(valp[1]) * F1
valp=v$values
# Calcul des coordonnées des individus sur les axes principaux
vectp = eigen(C)$vectors
apply(vectp,2,function(x){sum(x^2)}) # vecteurs normés
F1 = X%*%vectp[,1]                   # composante principale 1er axe
F2 = X%*%vectp[,2]                   # composante principale 2ème axe
X%*%vectp                            # composantes principales sur tous les axes
# Calcul des coordonnées des variables sur les axes principaux
G1 = cor(X,F1)
G2 = cor(X,F2)
valp=v$values
v1 = 1/sqrt(valp[1]) * F1
G1prime = cor(X,v1)
plot(F1,F2,xlab="Dim1",ylab="Dim2",type="n",
main="Nuage des individus")     # juste les axes
abline(v=0,h=0,lty=2)
val_ind=1:n                          # les labels
text(F1,F2,val_ind)
par(pty="s") #square plot region
plot(0,0,type="n",xlim=c(-1,1),ylim=c(-1,1),
xlab="Dim1",ylab="Dim2",main="Nuage des variables")
symbols(0,0,circles=1, inches=FALSE, add=TRUE)
abline(v=0,h=0,lty=2)
arrows(rep(0,7),rep(0,7),G1,G2)
val_var=colnames(X)                  # les labels
text(G1,G2,val_var)
library(FactoMineR)
help(PCA)
PCA(seeds)
############
#-- 5 PCA
############
library(FactoMineR)
par(mfrow=c(1,2))
res=PCA(seeds[,-p])
res              # comment accéder aux sorties
round(res$eig,4) # variance de chacun des 7 axes
sum(res$eig[,1])
barplot(res$eig[,2],main="% inertie",names=paste("Dim",1:nrow(res$eig)))
abline(h=100/7,lty=2)
12:16
### Etude des variables
V=res$var
plot(res,choix="var")
#qualité de représentation
V$cos2
V$cor^2
# corrélation
V$cor
cbind(G1,G2)
#contribution à l'axe
V$contrib
V$cos2[,1]/sum(V$cos2[,1])
#visualisation
par(mfrow=c(1,2))
plot(res, axes = c(1,2), choix = "var")
# axe 1 = effet taille
# axe 2 = opposition asymetrie - compacité
# axe 3 = compacité + asymétrie
plot(res, axes = c(2,3), choix = "var")
### Etude des individus
par(mfrow=c(1,2))
plot(res,axes = c(1,2), choix = "var")
plot(res,axes = c(1,2), choix = "ind",label="none")
Ind=res$ind
indi=c(19,39,58,89,90,95,178)
points(Ind$coord[indi,1],Ind$coord[indi,2],col="red",pch=20)
text(Ind$coord[indi,1],Ind$coord[indi,2],as.character(indi),pos=3,cex=0.7,col=2)
# contributions
apply(Ind$contrib,2,which.max)   # le plus contributif sur chaque axe
# Dim.1 Dim.2 Dim.3 Dim.4 Dim.5
# 89    19   204    60    60
head(sort(Ind$contrib[, 1],decreasing=TRUE)) # les premiers contibutifs du premier axe
# cosinus carré : qualité de représentration
which.max(Ind$cos2[,2]) #58
#on passe à la direction suivante
plot(res,axes = c(2,3), choix = "var")
plot(res,axes = c(2,3), choix = "ind",label="none")
points(Ind$coord[indi,2],Ind$coord[indi,3],col="red",pch=20)
text(res$ind$coord[indi,2],res$ind$coord[indi,3],as.character(indi),pos=3,cex=0.7,col=2)
### contributif et mal représenté sur l'axe 3
which(res$ind$cos2[,3]<0.15 & res$ind$contrib[,3]>1)
# 84  89  91 117 129 158
# 84  89  91 117 129 158
c(contrib=Ind$contrib[89,3],cos2= Ind$cos2[89,3])
### peu contributif mais bien représenté sur l'axe 2
which(res$ind$cos2[,2]>0.85 & res$ind$contrib[,2]<0.25) #39
### contributif et mal représenté sur l'axe 3
which(res$ind$cos2[,3]<0.15 & res$ind$contrib[,3]>1)
# 84  89  91 117 129 158
# 84  89  91 117 129 158
c(contrib=Ind$contrib[89,3],cos2= Ind$cos2[89,3])
### peu contributif mais bien représenté sur l'axe 2
which(res$ind$cos2[,2]>0.85 & res$ind$contrib[,2]<0.25) #39
c(contrib=Ind$contrib[39,2],cos2= Ind$cos2[39,2])
### contributif et bien représenté sur l'axe 2
which(res$ind$cos2[,2]>0.95 & res$ind$contrib[,2]>0.85) #58
Ind=res$ind
indi=c(19,39,58,89,90,95,178)
points(Ind$coord[indi,1],Ind$coord[indi,2],col="red",pch=20)
text(Ind$coord[indi,1],Ind$coord[indi,2],as.character(indi),pos=3,cex=0.7,col=2)
# contributions
apply(Ind$contrib,2,which.max)   # le plus contributif sur chaque axe
# Dim.1 Dim.2 Dim.3 Dim.4 Dim.5
# 89    19   204    60    60
head(sort(Ind$contrib[, 1],decreasing=TRUE)) # les premiers contibutifs du premier axe
# cosinus carré : qualité de représentration
which.max(Ind$cos2[,2]) #58
#on passe à la direction suivante
plot(res,axes = c(2,3), choix = "var")
plot(res,axes = c(2,3), choix = "ind",label="none")
points(Ind$coord[indi,2],Ind$coord[indi,3],col="red",pch=20)
text(res$ind$coord[indi,2],res$ind$coord[indi,3],as.character(indi),pos=3,cex=0.7,col=2)
### contributif et mal représenté sur l'axe 3
which(res$ind$cos2[,3]<0.15 & res$ind$contrib[,3]>1)
# 84  89  91 117 129 158
# 84  89  91 117 129 158
c(contrib=Ind$contrib[89,3],cos2= Ind$cos2[89,3])
### peu contributif mais bien représenté sur l'axe 2
which(res$ind$cos2[,2]>0.85 & res$ind$contrib[,2]<0.25) #39
c(contrib=Ind$contrib[39,2],cos2= Ind$cos2[39,2])
### contributif et bien représenté sur l'axe 2
which(res$ind$cos2[,2]>0.95 & res$ind$contrib[,2]>0.85) #58
c(contrib=Ind$contrib[58,2],cos2= Ind$cos2[58,2])
### Etude simultanée
par(mfrow=c(2,2))
plot(res,axes = c(1,2), choix = "ind",label="none")
plot(res,axes = c(2,3), choix = "ind",label="none")
plot(res,axes = c(1,2), choix = "var")
plot(res,axes = c(2,3), choix = "var")
install.packages("caret")
setwd("C:/Users/Yassine/Desktop/projets/TP STA212")
require(ElemStatLearn)
require(class)
require(caret)
load("mixture.example.rda")
data("mixture.example")
require(class)
require(caret)
load("mixture.example.rda")
data("mixture.example")
x <- mixture.example$x
dim(x)
head(x)
y <- mixture.example$y
table(y)
data("mixture.example")
x <- mixture.example$x
dim(x)
head(x)
y <- mixture.example$y
table(y)
trControl<-trainControl(method="cv",number=5)
K=c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
fit<-train(x,y,
method="knn",
tuneGrid = expand.grid(k=K),
trControl = trControl,
metric = "Accuracy")
plot(fit)
require(class)
require(caret)
data("mixture.example")
x <- mixture.example$x
dim(x)
head(x)
y <- as.factor(mixture.example$y)
table(y)
trControl<-trainControl(method="cv",number=5)
K=c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
fit<-train(x,y,
method="knn",
tuneGrid = expand.grid(k=K),
trControl = trControl,
metric = "Accuracy")
data("mixture.example")
x<-data.frame(mixture.example$x)
dim(x)
y<-as.factor(mixture.example$y)
table(y)
trControl<-trainControl(method ="cv",number =5)
install.packages("e1071")
require(e1071)
trControl<-trainControl(method="cv",number=5)
K=c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
fit<-train(x,y,
method="knn",
tuneGrid = expand.grid(k=K),
trControl = trControl,
metric = "Accuracy")
plot(fit)
trControl<-trainControl(method="repeatedcv",number=5,repeats=10)
K=c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
fit<-train(x,y,
method="knn",
tuneGrid = expand.grid(k=K),
trControl = trControl,
metric = "Accuracy")
plot(fit)
require(parallel)
require(doparallel)
install.packages("doParallel")
library(parallel)
library(doParallel)
require(class)
require(caret)
data("mixture.example")
x<-data.frame(mixture.example$x)
dim(x)
y<-as.factor(mixture.example$y)
table(y)
install.packages("e1071")
install.packages("e1071")
data("mixture.example")
x<-data.frame(mixture.example$x)
dim(x)
y<-as.factor(mixture.example$y)
table(y)
data("mixture.example")
x<-data.frame(mixture.example$x)
dim(x)
y<-as.factor(mixture.example$y)
data("mixture.example")
data("mixture.example")
x<-data.frame(mixture.example$x)
require(class)
require(caret)
data("mixture.example")
data("mixture.example.rda")
setwd("C:/Users/Yassine/Desktop/projets/TP STA212")
data("mixture.example")
x<-data.frame(mixture.example$x)
setwd("C:/Users/Yassine/Desktop/projets/TP STA212")
data("mixture.example")
require(class)
require(caret)
data("mixture.example")
setwd("C:/Users/Yassine/Desktop/projets/TP STA212")
x<-data.frame(mixture.example$x)
load("mixture_example.rda")
data("mixture.example")
x<-data.frame(mixture.example$x)
dim(x)
y<-as.factor(mixture.example$y)
table(y)
c1 <- makePSOCKcluster(6)
require(class)
require(caret)
library(parallel)
library(doParallel)
load("mixture_example.rda")
x<-data.frame(mixture.example$x)
dim(x)
y<-as.factor(mixture.example$y)
table(y)
c1 <- makePSOCKcluster(6)
registerDoParallel(c1)
trControl<-trainControl(method="repeatedcv",number=5,repeats=10)
K=c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
fit<-train(x,y,
method="knn",
tuneGrid = expand.grid(k=K),
trControl = trControl,
metric = "Accuracy")
stopCluster(c1)
plot(fit)
print(fit)
c1 <- makePSOCKcluster(6)
registerDoParallel(c1)
trControl<-trainControl(method="repeatedcv",number=5,repeats=100)
K=c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
fit<-train(x,y,
method="knn",
tuneGrid = expand.grid(k=K),
trControl = trControl,
metric = "Accuracy")
stopCluster(c1)
plot(fit)
print(fit)
c1 <- makePSOCKcluster(5)
registerDoParallel(c1)
trControl<-trainControl(method="repeatedcv",number=5,repeats=100)
K=c(1,3,5,7,9,11,15,17,23,25,35,45,55,83,101,151)
fit<-train(x,y,
method="knn",
tuneGrid = expand.grid(k=K),
trControl = trControl,
metric = "Accuracy")
stopCluster(c1)
plot(fit)
print(fit)
