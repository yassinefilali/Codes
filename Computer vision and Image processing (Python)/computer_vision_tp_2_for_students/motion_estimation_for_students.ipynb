{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "motion_estimation_for_students.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st0Rer20lXyu"
      },
      "source": [
        "# TP 2 : Computer Vision\n",
        "\n",
        "## Part 3 : motion estimation\n",
        "\n",
        "In this part of the TP, we are going to look at the following method for estimating motion :\n",
        "\n",
        "- block matching\n",
        "\n",
        "First, let us again load some packages and define some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ2xEyMtlXy4"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import numpy as np \n",
        "import imageio\n",
        "from skimage import color\n",
        "from scipy import signal\n",
        "from scipy.ndimage.morphology import binary_dilation\n",
        "\n",
        "is_colab = True\n",
        "\n",
        "def read_image(file_name):\n",
        "    img_color = imageio.imread(file_name)\n",
        "    img_gray = color.rgb2gray(img_color)\n",
        "    return img_gray,img_color\n",
        "    \n",
        "def write_image(img_in,file_name_out):\n",
        "    imageio.imwrite(file_name_out, np.uint8(255.0*img_in))\n",
        "    \n",
        "def display_image(img_in):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    if (img_in.ndim == 2):\n",
        "        plt.imshow(img_in,cmap='gray')\n",
        "    elif (img_in.ndim == 3):\n",
        "        # careful, in this case we supppose the pixel values are between 0 and 255\n",
        "        plt.imshow(np.uint8(img_in))\n",
        "    else:\n",
        "        print('Error, unknown number of dimensions in image')\n",
        "    return\n",
        "\n",
        "def display_motion(img_1,img_2,key_pts,motion,file_save=''):\n",
        "    \n",
        "    motion_x = motion[:,0]\n",
        "    motion_y = motion[:,1]\n",
        "    \n",
        "    img_size = img_1.shape\n",
        "    \n",
        "    head_width=2.0\n",
        "    head_length=3.0\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    ax = plt.imshow(img_1,cmap='gray')\n",
        "\n",
        "    print(key_pts.shape[0])\n",
        "    for i in range(0,key_pts.shape[0]):\n",
        "        x = key_pts[i,0]\n",
        "        y = key_pts[i,1]\n",
        "        plt.arrow(x,y, motion_x[i],motion_y[i] , color='r',\n",
        "            head_width=head_width, head_length=head_length,)\n",
        "    plt.gca().set_axis_off()\n",
        "    fig.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
        "                hspace = 0, wspace = 0)\n",
        "    plt.margins(0,0)\n",
        "    plt.gca().xaxis.set_major_locator(mpl.ticker.NullLocator())\n",
        "    plt.gca().yaxis.set_major_locator(mpl.ticker.NullLocator())\n",
        "\n",
        "    if (file_save != ''):\n",
        "        plt.savefig(file_save, bbox_inches = 'tight', pad_inches = 0)\n",
        "\n",
        "file_dir = 'images/'\n",
        "file_name_1 = 'afgrunden_1'\n",
        "file_name_2 = 'afgrunden_2'\n",
        "file_ext = '.png'\n",
        "\n",
        "if (is_colab == True):\n",
        "  !wget \"https://perso.telecom-paristech.fr/anewson/doc/images/afgrunden_1.png\"\n",
        "  !wget \"https://perso.telecom-paristech.fr/anewson/doc/images/afgrunden_2.png\"\n",
        "  img_1,_ = read_image(file_name_1+file_ext)\n",
        "  img_2,_ = read_image(file_name_2+file_ext)\n",
        "else:\n",
        "  img_1,_ = read_image(file_dir+file_name_1+file_ext)\n",
        "  img_2,_ = read_image(file_dir+file_name_2+file_ext)\n",
        "\n",
        "display_image(img_1)\n",
        "display_image(img_2)\n",
        "img_size = img_1.shape\n",
        "img_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYhm5AXhlXy7"
      },
      "source": [
        "__Question__ What sort of motion do you think is there between img_1 and img_2 ? You may want to flip between one image and another in an external viewer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-y6YAUvlXy8"
      },
      "source": [
        "__Answer__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQr3Ly92lXy8"
      },
      "source": [
        "## Block matching\n",
        "\n",
        "Block matching is a very intuitive algorithm for motion estimation. We choose a patch size, and for each patch $\\Psi_p$ in the first frame, we look for the patch $\\Psi_q$ which is the most similar, in a certain region around the original position. The motion $(\\delta_x,\\delta_y)$ is then defined as $(\\delta_x,\\delta_y) = q-p$, such that : \n",
        "\n",
        "$\n",
        "\\begin{cases}\n",
        "q_x = p_x+\\delta_x\\\\\n",
        "q_y = p_y+\\delta_y\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "The ''similarity'' between two patches is the sum of squared differences (SSD) :\n",
        "\n",
        "$d(\\Psi_p,\\Psi_q) = \\sum_{i \\Psi} \\left( I(p+i) - I(q+i) \\right)^2,$\n",
        "\n",
        "where $\\Psi$ is the patch neighbourhood (a square).\n",
        "\n",
        "We are going to be implementing block matching in a function called ``block_matching``. However, this can take a lot of time, so we only carry it out on a subset of the pixels, which we will call ``key_pts``. This will be a matrix of size $(N,2)$, where $N$ is the number of keypoints, and where each line has the following format :\n",
        "\n",
        "- $[x,y]$\n",
        "\n",
        "Create this function now, with the following parameters :\n",
        "\n",
        "- block_size = 7 (the patch size)\n",
        "- search_size = 15 (the maximum distance we search for the same patch in)\n",
        "\n",
        "You will have to deal with border conditions. There are two ways of doing this :\n",
        "\n",
        "- not allowing the patch search to go near to the borders (no closer than half the patch size)\n",
        "- making partial patch comparisons\n",
        "\n",
        "You can choose either method. The first is slightly easier to implement, but potentially incorrect near the borders. The second is more correct, but you have to make sure to make partial patch comparisons.\n",
        "\n",
        "Make sure you do __not__ carry out the patch distance calculation with a loop (which would not be very optimal). You can first create the patch neighbourhood $\\Psi$ with\n",
        "\n",
        "- ``np.meshgrid``\n",
        "\n",
        "and then take the SSD of the two patches.\n",
        "\n",
        "Fill in the following function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcLqwf8GlXy9"
      },
      "source": [
        "def block_matching(img_1,img_2,key_pts):\n",
        "    # FILL IN CODE HERE\n",
        "    return motion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4rYuO_tlXy-"
      },
      "source": [
        "We now draw some random keypoints to carry out the block matching on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_S_tE2SlXy-"
      },
      "source": [
        "n_pts = 80\n",
        "key_pts = np.zeros((n_pts,2)).astype(int)\n",
        "# a random seed, if you want repeatability\n",
        "np.random.seed(10)\n",
        "\n",
        "pixel_list = np.asarray(range(0,img_size[0]*img_size[1]))\n",
        "np.random.shuffle(pixel_list)\n",
        "key_pts = np.zeros((n_pts,2)).astype(int)\n",
        "key_pts[:,1],key_pts[:,0] = np.unravel_index(pixel_list[0:n_pts],img_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXcawJ46lXy_"
      },
      "source": [
        "key_pts[:,0].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaMdiMEwlXy_"
      },
      "source": [
        "Carry out the block matching and display the result with the ``display_motion`` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYx5Zb8ylXy_"
      },
      "source": [
        "motion = block_matching(img_1,img_2,key_pts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn6ZkaqXlXzA"
      },
      "source": [
        "display_motion(img_1,img_2,key_pts,motion)\n",
        "display_motion(img_1,img_2,key_pts,motion,file_name_1+'_motion_out.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUIqq2EblXzA"
      },
      "source": [
        "__Question__\n",
        "1/ Does the previous visualisation confirm your hypothesis concerning the type of motion ?\n",
        "2/ In what regions do you think the estimation might fail ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVS4ieyjlXzB"
      },
      "source": [
        "__Answer__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaAVnRAJlXzB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}